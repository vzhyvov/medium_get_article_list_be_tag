{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "\n",
    "\n",
    "def base_url_builder(tag):\n",
    "    #BUILDS THE BASE URL TO ITERATE ON FROM GIVEN TAG\n",
    "    url = \"https://medium.com/tag/\" + tag +\"/archive/\"\n",
    "    return url\n",
    "\n",
    "\n",
    "def get_start_date(year, month, day):\n",
    "    #CHECKS IF START DATE IS A VALID DATE, CONVERTS TO DATETIME OBJECT\n",
    "    try:\n",
    "        start_date = datetime(year, month, day)\n",
    "    except:\n",
    "        raise Exception(\"Start date is in the wrong format or is invalid.\")\n",
    "    return start_date\n",
    "\n",
    "\n",
    "def get_end_date(year, month, day):\n",
    "    #CHECKS IF END DATE IS A VALID DATE, CONVERTS TO DATETIME OBJECT\n",
    "    try:\n",
    "        end_date = datetime(year, month, day)\n",
    "    except:\n",
    "        raise Exception(\"End date is in the wrong format or is invalid.\")\n",
    "    return end_date\n",
    "\n",
    "\n",
    "def open_chrome():\n",
    "    #OPENS A CHROME DRIVER\n",
    "    driver = webdriver.Chrome()\n",
    "    driver.implicitly_wait(30)\n",
    "    return driver\n",
    "\n",
    "\n",
    "def url_masher(base_url, year, month, day):\n",
    "    #MAKES A NEW URL FRON GIVEN DATE\n",
    "    #THE FORMAT OF THE URL IS YYYY/MM/DD WE MUST MATCH IT\n",
    "    if len(month) == 1:\n",
    "        month = \"0\" + month\n",
    "    if len(day) == 1:\n",
    "        day = \"0\" + day\n",
    "    #MASH THE STRINGS TOGETHER TO MAKE A PASSABLE URL\n",
    "    url = base_url + year + \"/\" + month + \"/\" + day\n",
    "    return url\n",
    "\n",
    "\n",
    "\n",
    "def find_post_cards(soup):\n",
    "    #PULLS EACH CARD FROM THE FEED. EACH CARD IS A STORY OR COMMENT\n",
    "    cards = soup.find_all(\"div\", class_=\"streamItem streamItem--postPreview js-streamItem\")\n",
    "    return cards\n",
    "\n",
    "\n",
    "\n",
    "def get_titles_from_cards(cards):\n",
    "    #PULLS TITLE DATA FROM EACH CARD IN CARDS, RETURNS A LIST OF TITLES\n",
    "    def title_cleaner(title):\n",
    "        #REMOVE MEDIUMS ENCODING SYMBOLS AND EMOJIS FROM TITLES\n",
    "        title = title.replace(\"\\xa0\",\" \")\n",
    "        title = title.replace(\"\\u200a\",\"\")\n",
    "        title = title.replace(\"\\ufe0f\",\"\")\n",
    "        title = re.sub(r'[^\\x00-\\x7F]+','', title)\n",
    "        return title\n",
    "\n",
    "    titles=[]\n",
    "    for card in cards:\n",
    "        #SEARCH FOR TITLE THERE ARE 3 DIFF CLASSES\n",
    "        variant1 = card.find(\"h3\", class_=\"graf graf--h3 graf-after--figure graf--title\")\n",
    "        variant2 = card.find(\"h3\", class_=\"graf graf--h3 graf-after--figure graf--trailing graf--title\")\n",
    "        variant3 = card.find(\"h4\", class_=\"graf graf--h4 graf--leading\")\n",
    "        variant4 = card.find(\"h3\", class_=\"graf graf--h3 graf--leading graf--title\")\n",
    "        variant5 = card.find(\"p\", class_=\"graf graf--p graf--leading\")\n",
    "        variant6 = card.find(\"h3\", class_=\"graf graf--h3 graf--startsWithDoubleQuote graf--leading graf--title\")\n",
    "        variant7= card.find(\"h3\", class_=\"graf graf--h3 graf--startsWithDoubleQuote graf-after--figure graf--trailing graf--title\")\n",
    "        #EACH CARD MUST HAVE ONE OF THE ABOVE TITLE CLASSES FIND IT AND CUT OUT MEDIUM'S\n",
    "        #STYLING CODES\n",
    "        variants = [variant1, variant2, variant3, variant4, variant5, variant6, variant7]\n",
    "        saved = False\n",
    "        #THE FIRST TITLE ENTRY WE MATCH, WE SAVE\n",
    "        for variant in variants:\n",
    "            if ((variant is not None) and (not saved)):\n",
    "                title = variant.text\n",
    "                title = title_cleaner(title)\n",
    "                titles.append(title)\n",
    "                saved = True\n",
    "        if not saved:\n",
    "            titles.append(\"NaN\")\n",
    "    return titles\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_subtitles_from_cards(cards):\n",
    "    #PULLS TITLE DATA FROM EACH CARD IN CARDS, RETURNS A LIST OF TITLES\n",
    "    def subtitle_cleaner(subtitle):\n",
    "        #REMOVE MEDIUMS ENCODING SYMBOLS AND EMOJIS FROM TITLES\n",
    "        subtitle = subtitle.replace(\"\\xa0\",\" \")\n",
    "        subtitle = subtitle.replace(\"\\u200a\",\"\")\n",
    "        subtitle = subtitle.replace(\"\\ufe0f\",\"\")\n",
    "        subtitle = re.sub(r'[^\\x00-\\x7F]+','', subtitle)\n",
    "        return subtitle\n",
    "\n",
    "    subtitles=[]\n",
    "    for card in cards:\n",
    "        #SEARCH FOR TITLE THERE ARE 3 DIFF CLASSES\n",
    "        variant1 = card.find(\"h4\", class_=\"graf graf--h4 graf-after--h3 graf--subtitle\")\n",
    "        variant2 = card.find(\"h4\", class_=\"graf graf--h4 graf-after--h3 graf--trailing graf--subtitle\")\n",
    "        variant3 = card.find(\"strong\", class_=\"markup--strong markup--p-strong\")\n",
    "        variant4 = card.find(\"h4\", class_=\"graf graf--p graf-after--h3 graf--trailing\")\n",
    "        variant5= card.find(\"p\", class_=\"graf graf--p graf-after--h3 graf--trailing\")\n",
    "        variant6= card.find(\"blockquote\", class_=\"graf graf--pullquote graf-after--figure graf--trailing\")\n",
    "        variant7 = card.find(\"p\", class_=\"graf graf--p graf-after--figure\")\n",
    "        variant8 = card.find(\"blockquote\", class_=\"graf graf--blockquote graf-after--h3 graf--trailing\")\n",
    "        variant9 = card.find(\"p\", class_=\"graf graf--p graf-after--figure graf--trailing\")\n",
    "        variant10 = card.find(\"em\", class_=\"markup--em markup--p-em\")\n",
    "        variant11=card.find(\"p\", class_=\"graf graf--p graf-after--p graf--trailing\")\n",
    "        #EACH CARD MUST HAVE ONE OF THE TITLE CLASSES FIND IT AND CUT OUT MEDIUM'S\n",
    "        #STYLING CODES\n",
    "        variants = [variant1, variant2, variant3, variant4, variant5, variant6, variant7, variant8, variant9, variant10, variant11]\n",
    "        saved = False\n",
    "        for variant in variants:\n",
    "            if ((variant is not None) and (not saved)):\n",
    "                subtitle = variant.text\n",
    "                subtitle = subtitle_cleaner(subtitle)\n",
    "                subtitles.append(subtitle)\n",
    "                saved = True\n",
    "        if not saved:\n",
    "            subtitles.append(\"NaN\")\n",
    "    return subtitles\n",
    "\n",
    "\n",
    "\n",
    "def get_image_from_cards(cards):\n",
    "    #RETURNS A 1 IF IMAGE IS PRESENT\n",
    "    images = []\n",
    "    for card in cards:\n",
    "        img = card.find(\"img\",class_=\"progressiveMedia-image js-progressiveMedia-image\")\n",
    "        if img is not None:\n",
    "            images.append(1)\n",
    "        else:\n",
    "            images.append(0)\n",
    "    return images\n",
    "\n",
    "\n",
    "\n",
    "def get_auth_and_pubs_from_cards(cards):\n",
    "    # PULLS AUTHOR AND PUBLICATION FROM EACH STORY CARD\n",
    "    authors = []\n",
    "    pubs = []\n",
    "    for card in cards:\n",
    "        # get the author and publication\n",
    "        author = card.find(\"a\", class_=\"ds-link ds-link--styleSubtle link link--darken link--accent u-accentColor--textNormal u-accentColor--textDarken\")\n",
    "        pub = card.find(\"a\", class_=\"ds-link ds-link--styleSubtle link--darken link--accent u-accentColor--textNormal\")\n",
    "        if author is not None:\n",
    "            text = author.text\n",
    "            text = re.sub('\\s+[^A-Za-z]', '', text)\n",
    "            text = re.sub(r'[^\\x00-\\x7F]+',' ', text)\n",
    "            authors.append(text)\n",
    "        else:\n",
    "            authors.append(\"NaN\")\n",
    "        if pub is not None:\n",
    "            text2 = pub.text\n",
    "            text2 = re.sub('\\s+[^A-Za-z]', '', text2)\n",
    "            text2 = re.sub(r'[^\\x00-\\x7F]+',' ', text2)\n",
    "            pubs.append(text2)\n",
    "        else:\n",
    "            pubs.append(\"NaN\")\n",
    "    return authors, pubs\n",
    "\n",
    "\n",
    "def get_dates_and_tags(tag, year,month,day,cards):\n",
    "    #CREATES A LIST OF TAGS AND DATES\n",
    "    Year=[]\n",
    "    Month=[]\n",
    "    Day = []\n",
    "    tags=[]\n",
    "    for card in cards:\n",
    "        tags.append(tag)\n",
    "        Year.append(year)\n",
    "        Month.append(month)\n",
    "        Day.append(day)\n",
    "    return Year, Month, Day, tags\n",
    "\n",
    "\n",
    "def get_readTime_from_cards(cards):\n",
    "    #PULL READTIME FROM EACH CARD IN CARDS\n",
    "    readingTimes=[]\n",
    "    for card in cards:\n",
    "        time = card.find(\"span\", class_=\"readingTime\")\n",
    "        if time is not None:\n",
    "            time = time['title']\n",
    "            time = time.replace(\" min read\", \"\")\n",
    "            readingTimes.append(time)\n",
    "        else:\n",
    "            readingTimes.append(\"0\")\n",
    "    return readingTimes\n",
    "\n",
    "\n",
    "def get_applause_from_cards(cards):\n",
    "    #PULL CLAPS FROM CARDS\n",
    "    applause=[]\n",
    "    for card in cards:\n",
    "        claps=card.find(\"button\", class_=\"button button--chromeless u-baseColor--buttonNormal js-multirecommendCountButton u-disablePointerEvents\")\n",
    "        if claps is not None:\n",
    "            applause.append(claps.text)\n",
    "        else:\n",
    "            applause.append(\"0\")\n",
    "    return applause\n",
    "\n",
    "\n",
    "def get_comment_from_cards(cards):\n",
    "    #DETERMINES WHETHER THE TIMELINE CARD IS A COMMENT 1 IF COMMENT\n",
    "    comments = []\n",
    "    for card in cards:\n",
    "        comment = card.find(\"div\", class_=\"u-fontSize14 u-marginTop10 u-marginBottom20 u-padding14 u-xs-padding12 u-borderRadius3 u-borderCardBackground u-borderLighterHover u-boxShadow1px4pxCardBorder\")\n",
    "        if comment is not None:\n",
    "            comments.append(1)\n",
    "        else:\n",
    "            comments.append(0)\n",
    "    return comments\n",
    "\n",
    "\n",
    "\n",
    "def get_urls_from_cards(cards):\n",
    "    #GETS ARTICLE URLS FROM ALL CARDS\n",
    "    urls = []\n",
    "    for card in cards:\n",
    "        url = card.find(\"a\", class_=\"\")\n",
    "        if url is not None:\n",
    "            urls.append(url['href'])\n",
    "        else:\n",
    "            raise Exception(\"couldnt find a url\")\n",
    "    return urls\n",
    "\n",
    "def get_auth_urls_from_cards(cards):\n",
    "    #PULLS AUTHORS URL ADDRESS FROM EACH CARD\n",
    "    auth_urls = []\n",
    "    for card in cards:\n",
    "        url = card.find(\"a\", class_=\"ds-link ds-link--styleSubtle link link--darken link--accent u-accentColor--textNormal u-accentColor--textDarken\")\n",
    "        if url is not None:\n",
    "            auth_urls.append(url['href'])\n",
    "        else:\n",
    "            auth_urls.append(\"NaN\")\n",
    "    return auth_urls\n",
    "\n",
    "def scrape_tag(tag, yearstart, monthstart, yearstop, monthstop):\n",
    "    #-------------------------------------------------------------\n",
    "    #INPUT CHECKS\n",
    "    #1. MAKE SURE TAG IS VALID (no idea how to do this without exhaustive list... too much work )\n",
    "    #2.CHECK VALID FILE PATH\n",
    "    path = os.getcwd()\n",
    "    path = path + \"/TAG_SCRAPES/medium_\"+tag+\".csv\"\n",
    "    #3. TRY TO OPEN FILE PATH\n",
    "    try:\n",
    "        file = open(path, \"w\")\n",
    "        file.close()\n",
    "    except:\n",
    "        raise Exception(\"Could not open file.\")\n",
    "\n",
    "    #4. MAKE SURE START DATE <= STOP DATE\n",
    "    current_date = get_start_date(int(yearstart), int(monthstart), 1)\n",
    "    end_date = get_start_date(int(yearstop), int(monthstop), 1)\n",
    "    if current_date > end_date:\n",
    "        raise Exception(\"End date exceeds start date.\")\n",
    "    else:\n",
    "        None\n",
    "\n",
    "#-----------------------------------------------------------------\n",
    "    #BEGIN SCRAPE\n",
    "\n",
    "    #BUILDS THE BASE URL FROM GIVEN TAG TO ITERATE ON\n",
    "    base_url = base_url_builder(tag)\n",
    "    #MEDIUM DENIES ANY COMMANDLINE REQUESTS, NEED BROWSER\n",
    "    chrome_driver = open_chrome()\n",
    "\n",
    "    #USE FIRSTPAGE TO ADD HEADERS TO CSV, USE COUNTER TO GET COMMANDLINE PREVIEW OF PROGRESS\n",
    "    firstPage=True\n",
    "    counter=0\n",
    "\n",
    "    #START ITERATION OVER DATES\n",
    "    while(current_date <= end_date):\n",
    "        #BUILD URL FROM CURRENT_DATE\n",
    "        url = url_masher(base_url,\n",
    "                        str(current_date.year),\n",
    "                        str(current_date.month),\n",
    "                        str(current_date.day))\n",
    "\n",
    "        #PARSE WEB RESPONSE\n",
    "\n",
    "        response = chrome_driver.get(url)\n",
    "\n",
    "\n",
    "        soup = BeautifulSoup(chrome_driver.page_source, features='lxml')\n",
    "\n",
    "        #FIND ALL STORY CARDS, EACH IS AN ARTICLE\n",
    "        cards = find_post_cards(soup)\n",
    "\n",
    "        #PULL DATA FROM CARDS\n",
    "        titles = get_titles_from_cards(cards)\n",
    "        subtitles = get_subtitles_from_cards(cards)\n",
    "        images = get_image_from_cards(cards)\n",
    "        authors, pubs = get_auth_and_pubs_from_cards(cards)\n",
    "        year, month, day, tags = get_dates_and_tags(tag,\n",
    "                                        current_date.year,\n",
    "                                        current_date.month,\n",
    "                                        current_date.day,\n",
    "                                        cards)\n",
    "        readingTimes = get_readTime_from_cards(cards)\n",
    "        applause = get_applause_from_cards(cards)\n",
    "        urls = get_urls_from_cards(cards)\n",
    "        auth_urls = get_auth_urls_from_cards(cards)\n",
    "        comment = get_comment_from_cards(cards)\n",
    "\n",
    "        #ACCUMULATE DATA INTO A DICTIONARY\n",
    "        dict = {\"Title\":titles,\"Subtitle\":subtitles,\"Image\":images,\"Author\":authors, \"Publication\":pubs, \"Year\":year, \"Month\":month, \"Day\":day, \"Tag\":tags, \"Reading_Time\":readingTimes, \"Claps\":applause,\"Comment\":comment, \"url\":urls, \"Author_url\":auth_urls}\n",
    "\n",
    "        #CHECK THAT DATA IN EACH CATEGORY IS THE SAME LENGTH\n",
    "        vals = list(dict.values())\n",
    "        for col in vals:\n",
    "            if len(col)==len(cards):\n",
    "                continue\n",
    "            else:\n",
    "                raise Exception(\"Data length does not match number of stories on page.\")\n",
    "\n",
    "        #CREATE DATAFRAME TO ORGANIZE AND SAVE TO CSV\n",
    "        df = pd.DataFrame.from_dict(dict)\n",
    "\n",
    "        #APPEND DATA TO FILE,\n",
    "        # IF FIRSTPAGE-> ADD A HEADER\n",
    "        if firstPage:\n",
    "            with open(path, 'a') as f:\n",
    "                df.to_csv(f, mode=\"a\", header=True, index = False)\n",
    "            firstPage=False\n",
    "        #IF NOT FIRSTPAGE -> NO HEADER\n",
    "        else:\n",
    "            with open(path, 'a') as f:\n",
    "                df.to_csv(f, mode=\"a\", header=False, index=False)\n",
    "\n",
    "        #ADDS A DAY TO THE CURRENT DATE FOR NEXT URL CALL\n",
    "        current_date = current_date + timedelta(days=1)\n",
    "\n",
    "        #PRINTS THE NUMBER OF TOTAL TIMELINE CARDS SAVED TO CSV\n",
    "        counter = counter + len(cards)\n",
    "        print(counter, \"    \",current_date)\n",
    "        time.sleep(2)\n",
    "    chrome_driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "path = os.getcwd()\n",
    "path = path + \"/TAG_SCRAPES/medium_\"+\"tag\"+\".csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(path, \"w+\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
